# Gradient Descent

В данном разделе представлена собственная реализация различных алгоритмов градиентного спуска
для решения задачи регрессии.

* **[descents.py](./descents.py)**: **эффективная реализация градиентного спуска**:
  * для следующих **функций потерь** (с регуляризацией и без):
    * _MSE_
    * _MAE_
    * _LogCosh_
    * _Huber-loss_
  * и **алгоритмов градиентного спуска**:
    * полный градиентный спуск (_FGD_)
    * стохастический градиентный спуск (_SGD_)
    * градиентный спуск с методом инерции (_Momentum_)
    * градиентный спуск с адаптивным шагом (_Adam_)
* **[linear_regression.py](./linear_regression.py)**: программная **реализация линейной регрессии**:
  * с регуляризацией
  * без регуляризации
* **[practice-03-gd-Rubanov.ipynb](./practice-03-gd-Rubanov.ipynb)**: **сравнение** реализованных
алгоритмов по различным параметрам. Кроме того, **разведочный анализ данных** (EDA) и **визуализация**
результатов работы алгоритмов.
