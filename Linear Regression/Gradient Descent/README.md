# Gradient Descent

В данном разделе представлена собственная реализация различных алгоритмов градиентного спуска
для решения задачи регрессии. 

* **[descents.py](./descents.py)**: эффективная реализация градиентого спуска:
  * для следующих функций потерь (с регуляризацией и без):
    * MSE
    * MAE
    * LogCosh
    * Huber-loss
  * и алгоритмов градиентого спуска:
    * полный градиентный спуск (FGD)
    * стохастический градиентный спуск (SGD)
    * градиентный спуск с методом инерции (Momentum)
    * градиентный спуск с адаптивным шагом (Adam)
* **[linear_regression.py](./linear_regression.py)**: программная реализация линейной регрессии:
  * с регуляризацией
  * без регуляризации
* **[practice-03-gd-Rubanov.ipynb](./practice-03-gd-Rubanov.ipynb)**: сравнение реализованных
алгоритмов по различным параметрам. Кроме того, разведочный анализ данных (EDA) и визуализация
результатов работы алгоритмов.
